
      <!DOCTYPE html>
      <html lang="en">
        <head>
          <meta charset="UTF-8">
          <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
          <meta name="viewport" content="width=device-width, initial-scale=1.0">
          <title>Project 90</title>
          <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            .ql-editor p { margin: 10px 0; }
            .ql-editor h1 { font-size: 24px; font-weight: bold; }
            .ql-editor h2 { font-size: 20px; font-weight: bold; }
            .ql-editor h3 { font-size: 16px; font-weight: bold; }
            .ql-editor strong { font-weight: bold; }
            .ql-editor em { font-style: italic; }
            .ql-editor u { text-decoration: underline; }
            .ql-editor img { max-width: 100%; height: auto; display: block; }
            .ql-align-center { text-align: center; }
            .ql-align-right { text-align: right; }
            .ql-align-justify { text-align: justify; }
          </style>
        </head>
        <body>
          <h2>Project Details</h2>
          <p><strong>Workstream:</strong> AI</p>
          <p><strong>Title:</strong> AI Neural Schema</p>
          <p><strong>Deadline:</strong> 2025-12-01</p>
          <p><strong>Budget:</strong> 2000000</p>
          <h3>Description:</h3>
          <div class="ql-editor"><h2><strong>Robotic Neural Schema Description</strong></h2><p>The <strong style="background-color: rgb(255, 153, 0);">Robotic Neural Schema</strong><span style="background-color: rgb(255, 153, 0);"> represents</span> the computational and sensory framework that enables the robot to perceive, process, and respond to its environment in an adaptive and intelligent manner. It is inspired by biological neural systems and integrates hardware (sensors, actuators, processors) with software (neural networks, control algorithms, and decision-making models).</p><h3><strong>1. Sensory Input Layer</strong></h3><ul><li><strong>Vision Sensors</strong>: Cameras, LiDAR, or depth sensors for object detection, mapping, and navigation.</li><li><strong>Proprioceptive Sensors</strong>: Encoders, gyroscopes, and accelerometers for balance, movement, and orientation.</li><li><strong>Tactile Sensors</strong>: Pressure pads and force sensors for grasping and interaction.</li><li><strong>Auditory Sensors</strong>: Microphones for speech recognition and sound localization.</li></ul><blockquote><em>Role</em>: Collect real-time environmental and internal state data to feed into the processing unit.</blockquote><p><br></p></div>
          <p><em>Note: If images do not display in Microsoft Word, open this file in a web browser first or rename it to .doc manually.</em></p>
        </body>
      </html>
    